{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3cc8ab",
   "metadata": {},
   "source": [
    "\n",
    "## **Assignment: Dimensionality Reduction on Suitable Datasets**  \n",
    "\n",
    "**Objective:** Apply dimensionality reduction techniques to datasets where they are most appropriate and analyze their effectiveness.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Task Description**  \n",
    "You will apply **8 dimensionality reduction methods** to **4 datasets** chosen for their compatibility with specific techniques. Your goal is to:  \n",
    "1. Reduce dimensions while preserving structure.  \n",
    "2. Critically evaluate why certain methods suit specific datasets.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Datasets & Methods**  \n",
    "| **Dataset**               | **Techniques**                                  | **Reason**                                                                 | **Load Data**                                                                                     |  \n",
    "|---------------------------|------------------------------------------------|---------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|  \n",
    "| **MNIST**                  | PCA, t-SNE, UMAP, KPCA, Autoencoder            | Image data with spatial correlations; ideal for linear/non-linear methods.| ``` from tensorflow.keras.datasets import mnist; (X_train, y_train), (X_test, y_test) = mnist.load_data() ``` |  \n",
    "| **Titanic (categorical)** | MCA                                            | Mixed categorical variables (e.g., class, sex, embarked).                 | ``` import seaborn as sns; titanic = sns.load_dataset('titanic') ```                        |  \n",
    "| **EEG Signals**            | ICA                                            | Blind source separation for time-series signals.                          | ``` import mne; from mne.datasets import sample; data_path = sample.data_path(); raw = mne.io.read_raw_fif(data_path / 'MEG' / 'sample' / 'sample_audvis_filt-0-40_raw.fif') ``` |  \n",
    "| **Psychological Survey**  | FA                                             | Latent factor discovery in Likert-scale questionnaire data.               | ``` import numpy as np; X = np.random.randint(1, 6, size=(500, 20)) ```                     |  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Explanation of Load Data Column**\n",
    "1. **MNIST**:  \n",
    "   - Use `tensorflow.keras.datasets.mnist` to load the dataset.  \n",
    "   - The dataset is split into training and testing sets by default.  \n",
    "\n",
    "2. **Titanic**:  \n",
    "   - Use `seaborn.load_dataset('titanic')` to load the dataset directly.  \n",
    "   - Alternatively, you can download it from Kaggle.  \n",
    "\n",
    "3. **EEG Signals**:  \n",
    "   - Use the `mne` library to load a sample EEG dataset.  \n",
    "   - The `sample_audvis_filt-0-40_raw.fif` file contains preprocessed EEG data.  \n",
    "\n",
    "4. **Psychological Survey**:  \n",
    "   - Simulate synthetic data using `numpy.random.randint` to create a dataset of 500 respondents and 20 Likert-scale questions.  \n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you need further clarification or help with implementing the dimensionality reduction techniques!\n",
    "---\n",
    "\n",
    "### **Requirements**  \n",
    "####  **Data Preparation**  \n",
    "   - **MNIST**: Load 10,000 samples, normalize to `[0, 1]`.  \n",
    "   - **Titanic**: Use categorical features (e.g., `pclass`, `sex`, `embarked`).  \n",
    "   - **EEG Signals**: Use `mne.datasets.sample.data_path()` or a synthetic signal dataset.  \n",
    "   - **Psychological Survey**: Simulate data with 20 Likert-scale questions (1–5) for 500 respondents.  \n",
    "\n",
    "####  **Dimensionality Reduction**  \n",
    "   - **MNIST**: Apply PCA, t-SNE, UMAP, KPCA (RBF kernel), and a simple autoencoder (2D/3D latent space).  \n",
    "   - **Titanic**: Use MCA (`prince.MCA`) on categorical features.  \n",
    "   - **EEG Signals**: Apply ICA (`FastICA`) to separate 2–3 latent sources.  \n",
    "   - **Psychological Survey**: Use FA (`FactorAnalysis`) to extract 2–3 latent factors.  \n",
    "\n",
    "####  **Visualization & Evaluation**  \n",
    "   - **MNIST**:  \n",
    "     - Visualize 2D/3D embeddings colored by digit labels.  \n",
    "     - Compute **reconstruction error (MSE)** for PCA/KPCA/Autoencoder.  \n",
    "     - Train a logistic regression classifier on 2D features and report accuracy.  \n",
    "   - **Titanic**:  \n",
    "     - Plot MCA embeddings colored by `survived` status.  \n",
    "     - Interpret category contributions to dimensions.  \n",
    "   - **EEG Signals**:  \n",
    "     - Plot separated ICA components and compare to raw signals.  \n",
    "   - **Psychological Survey**:  \n",
    "     - Interpret FA factors (e.g., \"neuroticism\" vs. \"openness\").  \n",
    "\n",
    "####  **Comparison**  \n",
    "   - For MNIST methods: Compare runtime, reconstruction error, and classification accuracy.  \n",
    "   - For all methods: Write a brief reflection on why the dataset was suitable for the technique.  \n",
    "\n",
    "####  **Critical Analysis**  \n",
    "Answer:  \n",
    "   - Why is MCA a better fit for Titanic than MNIST?  \n",
    "   - How does ICA’s assumption of non-Gaussianity help with EEG signals?  \n",
    "   - When would you prefer FA over PCA for survey data?  \n",
    "   - Why do autoencoders outperform PCA on MNIST (if they do)?  \n",
    "\n",
    "---\n",
    "\n",
    "### **Deliverables**  \n",
    "1. **Code**: Separate Python scripts/Jupyter notebooks for each dataset.  \n",
    "2. **Visualizations**: Embeddings, component plots, and factor interpretations.  \n",
    "---\n",
    "\n",
    "\n",
    "### **Tips**  \n",
    "- For ICA on EEG data, use `mne.preprocessing.ICA` for practical relevance.  \n",
    "- Simulate survey data using `np.random.randint(1, 6, size=(500, 20))`.  \n",
    "- Use `plotly` for interactive 3D visualizations of MNIST embeddings.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Good Luck!**  \n",
    "*“Without data, you’re just a person with an opinion.” – W. Edwards Deming*  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
